{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compilation of test data for performance tests\n",
    "\n",
    "This notebook records the parameters for Wright-Fisher simulations used to generate our test data sets, as well as commands for running covariance estimation algorithms on the test data and compiling the results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import required libraries and define global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This notebook was prepared using:\n",
      "python version 3.6.10 |Anaconda, Inc.| (default, Mar 25 2020, 18:53:43) \n",
      "[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]\n",
      "numpy version 1.19.1\n",
      "seaborn version 0.11.0\n",
      "matplotlib version 3.3.2\n",
      "scipy version 1.5.2\n"
     ]
    }
   ],
   "source": [
    "# Full library list and version numbers\n",
    "\n",
    "print('This notebook was prepared using:')\n",
    "\n",
    "import sys\n",
    "print('python version %s' % sys.version)\n",
    "\n",
    "import numpy as np\n",
    "print('numpy version %s' % np.__version__)\n",
    "\n",
    "import seaborn as sns\n",
    "print('seaborn version %s' % sns.__version__)\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "print('matplotlib version %s' % mpl.__version__)\n",
    "\n",
    "import scipy\n",
    "from scipy import stats\n",
    "print('scipy version %s' % scipy.__version__)\n",
    "\n",
    "# GLOBAL VARIABLES\n",
    "\n",
    "N = 1000        # number of sequences in the population\n",
    "L = 50          # sequence length\n",
    "T = 700         # number of generations\n",
    "MU = 1e-3       # mutation rate\n",
    "num_selections = 10  # number of sets of selection coefficients that we used\n",
    "num_trials = 20  # for each set of selection coefficients, we simulated for 20 times\n",
    "SAMPLE = [1000, 500, 100, 50, 10]  # sampling depth options when subsampling\n",
    "RECORD = [1, 3, 5, 10]  # sampling time interval options when subsampling\n",
    "LINEAR = [1, 5, 10, 20, 50, 100, 300]  # list of linear shrinkage strengths/sampling time intervals, e.g., interval=5, linear=5 ==> strength=25'\n",
    "GAMMA = [5e-5, 5e-4, 5e-3, 5e-2, 5e-1, 1]  # non-linear shrinkage parameter choices that we tested\n",
    "TRUNCATE = [200, 300, 400, 500, 600, 700]  # truncate options to test performance using different lengths of data\n",
    "WINDOW = [0, 1, 2, 3, 4, 5, 10, 20, 40, 80, 160]  # window choices that we tested\n",
    "# loss functions for non-linear shrinkage that we tested\n",
    "LOSS = ['Fro | $\\hat{C}-C$', 'Fro | $\\hat{C}^{-1}-C^{-1}$', 'Fro | $C^{-1}\\hat{C}-I$', \n",
    "        'Fro | $\\hat{C}^{-1}C-I$', 'Fro | $\\hat{C}^{-1/2}C\\hat{C}^{-1/2}-I$', \n",
    "        'Nuc | $\\hat{C}-C$', 'Nuc | $\\hat{C}^{-1}-C^{-1}$', 'Nuc | $C^{-1}\\hat{C}-I$', \n",
    "        'Nuc | $\\hat{C}^{-1}C-I$', 'Nuc | $\\hat{C}^{-1/2}C\\hat{C}^{-1/2}-I$'] \n",
    "\n",
    "# GitHub directories\n",
    "DATA_DIR = './data'\n",
    "SELECTION_DIR = './src/selection'\n",
    "INITIAL_DIR = './src/initial'\n",
    "SIMULATION_OUTPUT_DIR = './data/simulation_output'\n",
    "SUBSAMPLE_OUTPUT_DIR = './data/subsample_output'\n",
    "ESTIMATION_OUTPUT_DIR = './data/estimation_output'\n",
    "JOB_DIR = './src/jobs'\n",
    "\n",
    "# relative directories looking from shell scripts in JOB_DIR\n",
    "SRC_DIR_REL = '..'\n",
    "DATA_DIR_REL = '../../data'\n",
    "SELECTION_DIR_REL = '../../src/selection'\n",
    "INITIAL_DIR_REL = '../../src/initial'\n",
    "SIMULATION_OUTPUT_DIR_REL = '../../data/simulation_output'\n",
    "SUBSAMPLE_OUTPUT_DIR_REL = '../../data/subsample_output'\n",
    "ESTIMATION_OUTPUT_DIR_REL = '../../data/estimation_output'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1. Generation of test data through Wright-Fisher simulationsÂ¶\n",
    "\n",
    "Wright-Fisher simulations are performed using src/Wright-Fisher.py. The output of these simulations is saved for processing. The code below creates multiple job files for running many simulations in parallel on a computer cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_selection_coefficients():\n",
    "    \"\"\"Generates 10 sets of selection coefficients.\n",
    "    \n",
    "    This was how the 10 sets of selection coefficients were generated. \n",
    "    Note that since some selectons are randomly sampled, re-run this will yield different selections.\n",
    "    \"\"\"\n",
    "    s = np.zeros((num_selections, L, L), dtype = float)\n",
    "    sign = np.zeros(2, dtype = int)\n",
    "    sign[0] = 1\n",
    "    sign[1] = -1\n",
    "    for n in range(4):\n",
    "        num_nonneutral = 10 * (n + 1)\n",
    "        for i in range(num_nonneutral):\n",
    "            s[n, i] = 0.05 - 0.1 * i / num_nonneutral\n",
    "\n",
    "    for n in range(4, num_selections):\n",
    "        num_nonneutral = 30\n",
    "        for i in range(num_nonneutral):\n",
    "            s[n, i] = np.random.choice(sign) * np.random.normal(0.03, 0.01)\n",
    "            \n",
    "    for n in range(num_selections):\n",
    "        np.save(SELECTION_DIR + f'/selection_newly_generated_{n}.npy', s[n])\n",
    "\n",
    "        \n",
    "def generate_initial_distribution():\n",
    "    \"\"\"Generates the initial distribution of genotypes used in our simulations.\n",
    "    \n",
    "    This was how the initial distribution of genotypes were generated. \n",
    "    Initially the population mainly consists of three genotypes, each starting with 333 sequences. \n",
    "    For every 7 alleles, 1 allele is mutant in all three genotypes. 3 allele are mutant in two genotypes; \n",
    "    The other 3 are mutant in only one of three genotypes. \n",
    "    \"\"\" \n",
    "    sequences = []\n",
    "    counts = []\n",
    "    seq = np.zeros((3, L), dtype = int)\n",
    "    for n in range(7):\n",
    "        seq[0, 7 * n] = seq[1, 7 * n] = seq[2, 7 * n] = 1\n",
    "        seq[0, 7 * n + 1] = seq[1, 7 * n + 1] = 1\n",
    "        seq[1, 7 * n + 2] = seq[2, 7 * n + 2] = 1\n",
    "        seq[0, 7 * n + 3] = seq[2, 7 * n + 3] = 1\n",
    "        seq[0, 7 * n + 4] = 1\n",
    "        seq[1, 7 * n + 5] = 1\n",
    "        seq[2, 7 * n + 6] = 1\n",
    "    \n",
    "    sequences.append(np.array([int(i) for i in seq[0]]))\n",
    "    counts.append(N//3)\n",
    "    sequences.append(np.array([int(i) for i in seq[1]]))\n",
    "    counts.append(N//3)\n",
    "    sequences.append(np.array([int(i) for i in seq[2]]))\n",
    "    counts.append(N//3)\n",
    "    sequences.append(np.array([int(i) for i in CM.bin(0, L)]))\n",
    "    counts.append(N - int(N//3) * 3)\n",
    "    \n",
    "    np.savez_compressed(INITIAL_DIR + '/initial', sequences = sequences, counts = counts)\n",
    "    \n",
    "    \n",
    "def print_initial_distribution(init_dist):\n",
    "    \"\"\"Prints initial genotypes and their counts.\"\"\"\n",
    "    \n",
    "    for i, seq in enumerate(init_dist['sequences']):\n",
    "        print(f'Genotype {i+1}', ''.join([str(allele) for allele in seq]), f'count={init_dist[\"counts\"][i]}')\n",
    "       \n",
    "    \n",
    "def generate_shell_script(path2job, jobname, command, hours=4, mem=16, ncpus=1, env='env_pySCA'):\n",
    "    \"\"\"Generates a shell script to run on HPCC cluster.\"\"\"\n",
    "    \n",
    "    fp = open(path2job + '/' + jobname + '.sh', 'w')\n",
    "    fp.write('#!/bin/bash -l\\n')\n",
    "    fp.write(f'#SBATCH --nodes=1\\n#SBATCH --ntasks=1\\n')\n",
    "    fp.write(f'#SBATCH --cpus-per-task={ncpus}\\n')\n",
    "    fp.write(f'#SBATCH --mem={mem}G\\n#SBATCH --time={hours}:00:00\\n')\n",
    "    fp.write(f'#SBATCH --output={jobname}.stdout\\n')\n",
    "    fp.write(f'#SBATCH --job-name=\"{jobname}\"\\n')\n",
    "    fp.write(f'date\\nsource activate {env}\\n')\n",
    "    fp.write(command)\n",
    "    fp.write('\\ndate')\n",
    "    fp.close()\n",
    "    \n",
    "    \n",
    "def load_selection(s):\n",
    "    \"\"\"Loads one of 10 sets of selection coefficients.\"\"\"\n",
    "    \n",
    "    return np.load(SELECTION_DIR + f'/selection_{s}.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genotype 1 11011001101100110110011011001101100110110011011000 count=333\n",
      "Genotype 2 11100101110010111001011100101110010111001011100100 count=333\n",
      "Genotype 3 10110011011001101100110110011011001101100110110010 count=333\n",
      "Genotype 4 00000000000000000000000000000000000000000000000000 count=1\n"
     ]
    }
   ],
   "source": [
    "# 10 sets of selection coefficients used for simulations\n",
    "selections = np.zeros((num_selections, L), dtype=float)\n",
    "for s in range(num_selections):\n",
    "    selections[s] = load_selection(s)\n",
    "        \n",
    "# initial distribution of genotypes in the population\n",
    "initial = np.load(INITIAL_DIR + f'/initial.npz')\n",
    "print_initial_distribution(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In total, num_selections x num_trials = 200 simulations\n",
    "for s in range(num_selections):\n",
    "    for n in range(num_trials):\n",
    "        jobname = f'simulation_s={s}_n={n}'\n",
    "        job_pars = {'-N': N,\n",
    "                    '-L': L,\n",
    "                    '-T': T,\n",
    "                    '-i': f'{INITIAL_DIR_REL}/initial.npz',\n",
    "                    '-s': f'{SELECTION_DIR_REL}/selection_{s}.npy',\n",
    "                    '-o': f'{SIMULATION_OUTPUT_DIR_REL}/simulation_output_s={s}_n={n}',\n",
    "                    '--mu': MU}\n",
    "        command = 'python ../Wright-Fisher.py '\n",
    "        command += ' '.join([k + ' ' + str(v) for k, v in job_pars.items()])\n",
    "        command += '\\n'\n",
    "        generate_shell_script(JOB_DIR, jobname, command, hours=1)\n",
    "    \n",
    "jobname = 'simulation_submission'\n",
    "command = ''\n",
    "for s in range(num_selections):\n",
    "    for n in range(num_trials):\n",
    "        command += f'sbatch simulation_s={s}_n={n}.sh\\n'\n",
    "generate_shell_script(JOB_DIR, jobname, command)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2. Subsample the simulated results for later inference under various limited sampling scenarios\n",
    "We subsample the simulated results varying sampling depth and time interval. The output of is saved for investigating performance of inference under different limited sampling effects. The code below creates multiple files for running many subsampling jobs in parallel on a computer cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In total, num_selections x num_trials x len(SAMPLE) x len(RECORD) = 4000 subsampling runs, put as 200 jobs\n",
    "for s in range(num_selections):\n",
    "    for n in range(num_trials):\n",
    "        jobname = f'subsample_s={s}_n={n}'\n",
    "        command = ''\n",
    "        for sample in SAMPLE:\n",
    "            for record in RECORD:\n",
    "                job_pars = {'-i': f'{SIMULATION_OUTPUT_DIR_REL}/simulation_output_s={s}_n={n}.npz', \n",
    "                            '-o': f'{SUBSAMPLE_OUTPUT_DIR_REL}/subsample_output_s={s}_n={n}_sample={sample}_record={record}', \n",
    "                            '--sample': sample, \n",
    "                            '--record': record, \n",
    "                            '--compact': '',\n",
    "                            '--intCovAtTimes': ''}\n",
    "                command += 'python ../subsample.py '\n",
    "                command += ' '.join([k + ' ' + str(v) for k, v in job_pars.items()])\n",
    "                command += '\\n'\n",
    "        generate_shell_script(JOB_DIR, jobname, command, hours=1)\n",
    "jobname = 'subsample_submission'\n",
    "command = ''\n",
    "for s in range(num_selections):\n",
    "    for n in range(num_trials):\n",
    "        command += f'sbatch subsample_s={s}_n={n}.sh\\n'\n",
    "generate_shell_script(JOB_DIR, jobname, command)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3. Running the covariance estimation algorithms and compiling output\n",
    "Finally we estimate covariance and infer selection coefficients for all subsampled cases generated above. The output of is saved for plotting. The code below creates multiple files to run in parallel on a computer cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In total, len(TRUNCATE) x len(WINDOW) = 42 jobs\n",
    "for tr in TRUNCATE:\n",
    "    for win in WINDOW:\n",
    "        jobname = f'estimate_truncate={tr}_window={win}'\n",
    "        command = ''\n",
    "        job_pars = {'-N': N,\n",
    "                    '-L': L,\n",
    "                    '-T': T,\n",
    "                    '-truncate': tr,\n",
    "                    '-window': win,\n",
    "                    '-num_selections': num_selections,\n",
    "                    '-num_trials': num_trials,\n",
    "                    '-s': f'{SELECTION_DIR_REL}/selection',\n",
    "                    '-i': f'{SUBSAMPLE_OUTPUT_DIR_REL}/subsample_output', \n",
    "                    '-o': f'{ESTIMATION_OUTPUT_DIR_REL}/estimation_output', \n",
    "                    '--minimal_size': ''}\n",
    "        command += 'python ../estimate.py '\n",
    "        command += ' '.join([k + ' ' + str(v) for k, v in job_pars.items()])\n",
    "        command += '\\n'\n",
    "        generate_shell_script(JOB_DIR, jobname, command, hours=8)\n",
    "jobname = 'estimate_submission'\n",
    "command = ''\n",
    "for tr in TRUNCATE:\n",
    "    for win in WINDOW:\n",
    "        command += f'sbatch estimate_truncate={tr}_window={win}.sh\\n'\n",
    "generate_shell_script(JOB_DIR, jobname, command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_anaconda3)",
   "language": "python",
   "name": "conda_anaconda3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
